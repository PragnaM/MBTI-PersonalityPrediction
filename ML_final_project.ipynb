{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sASaPlGqTlB1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "5619d74d-11e1-4c79-89fe-44dbcde29c0e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   type                                              posts\n",
              "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
              "1  ENTP  'I'm finding the lack of me in these posts ver...\n",
              "2  INTP  'Good one  _____   https://www.youtube.com/wat...\n",
              "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...\n",
              "4  ENTJ  'You're fired.|||That's another silly misconce..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5dfde3d3-dffb-4f97-a60a-276f13a6d593\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>posts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>INFJ</td>\n",
              "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ENTP</td>\n",
              "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>INTP</td>\n",
              "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>INTJ</td>\n",
              "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ENTJ</td>\n",
              "      <td>'You're fired.|||That's another silly misconce...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5dfde3d3-dffb-4f97-a60a-276f13a6d593')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5dfde3d3-dffb-4f97-a60a-276f13a6d593 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5dfde3d3-dffb-4f97-a60a-276f13a6d593');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ],
      "source": [
        "#Reading data from csv file\n",
        "import pandas as pd\n",
        "data = pd.read_csv('mbti_1.csv')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking for null values\n",
        "data.isnull().any()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVLSYvmXQrGa",
        "outputId": "a5db7681-a323-497d-ca01-0c773f3524b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "type     False\n",
              "posts    False\n",
              "dtype: bool"
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting MBTI types to different axes\n",
        "def get_types(row):\n",
        "    t=row['type']\n",
        "\n",
        "    I = 0; N = 0\n",
        "    T = 0; J = 0\n",
        "    \n",
        "    if t[0] == 'I': I = 1\n",
        "    elif t[0] == 'E': I = 0\n",
        "    else: print('I-E not found') \n",
        "        \n",
        "    if t[1] == 'N': N = 1\n",
        "    elif t[1] == 'S': N = 0\n",
        "    else: print('N-S not found')\n",
        "        \n",
        "    if t[2] == 'T': T = 1\n",
        "    elif t[2] == 'F': T = 0\n",
        "    else: print('T-F not found')\n",
        "        \n",
        "    if t[3] == 'J': J = 1\n",
        "    elif t[3] == 'P': J = 0\n",
        "    else: print('J-P not found')\n",
        "    return pd.Series( {'IE':I, 'NS':N , 'TF': T, 'JP': J }) \n",
        "\n",
        "data = data.join(data.apply (lambda row: get_types (row),axis=1))\n",
        "data.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "DlKByXukRD6G",
        "outputId": "7d511dc3-6fa3-4f8a-ba20-df8a5f172c33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   type                                              posts  IE  NS  TF  JP\n",
              "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...   1   1   0   1\n",
              "1  ENTP  'I'm finding the lack of me in these posts ver...   0   1   1   0\n",
              "2  INTP  'Good one  _____   https://www.youtube.com/wat...   1   1   1   0\n",
              "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...   1   1   1   1\n",
              "4  ENTJ  'You're fired.|||That's another silly misconce...   0   1   1   1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3722acdf-b504-46ca-b077-99f7f3539f1e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>posts</th>\n",
              "      <th>IE</th>\n",
              "      <th>NS</th>\n",
              "      <th>TF</th>\n",
              "      <th>JP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>INFJ</td>\n",
              "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ENTP</td>\n",
              "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>INTP</td>\n",
              "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>INTJ</td>\n",
              "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ENTJ</td>\n",
              "      <td>'You're fired.|||That's another silly misconce...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3722acdf-b504-46ca-b077-99f7f3539f1e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3722acdf-b504-46ca-b077-99f7f3539f1e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3722acdf-b504-46ca-b077-99f7f3539f1e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Count of posts with each type\n",
        "print (\"Introversion (I) /  Extroversion (E):\\t\", data['IE'].value_counts()[0], \" / \", data['IE'].value_counts()[1])\n",
        "print (\"Intuition (N) / Sensing (S):\\t\\t\", data['NS'].value_counts()[0], \" / \", data['NS'].value_counts()[1])\n",
        "print (\"Thinking (T) / Feeling (F):\\t\\t\", data['TF'].value_counts()[0], \" / \", data['TF'].value_counts()[1])\n",
        "print (\"Judging (J) / Perceiving (P):\\t\\t\", data['JP'].value_counts()[0], \" / \", data['JP'].value_counts()[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5I6KQYDROYs",
        "outputId": "5f162176-9842-4479-d7e7-cd15833f6c95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Introversion (I) /  Extroversion (E):\t 1999  /  6676\n",
            "Intuition (N) / Sensing (S):\t\t 1197  /  7478\n",
            "Thinking (T) / Feeling (F):\t\t 4694  /  3981\n",
            "Judging (J) / Perceiving (P):\t\t 5241  /  3434\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting the distribution of each personality type indicator\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "N = 4\n",
        "bottom = (data['IE'].value_counts()[0], data['NS'].value_counts()[0], data['TF'].value_counts()[0], data['JP'].value_counts()[0])\n",
        "top = (data['IE'].value_counts()[1], data['NS'].value_counts()[1], data['TF'].value_counts()[1], data['JP'].value_counts()[1])\n",
        "\n",
        "ind = np.arange(N)    # the x locations for the groups\n",
        "# the width of the bars\n",
        "width = 0.7           # or len(x) can also be used here\n",
        "\n",
        "p1 = plt.bar(ind, bottom, width, label=\"I, N, T, F\")\n",
        "p2 = plt.bar(ind, top, width, bottom=bottom, label=\"E, S, F, P\") \n",
        "\n",
        "plt.title('Distribution accoss types indicators')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(ind, ('I / E',  'N / S', 'T / F', 'J / P',))\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "PdL_6-24RTZU",
        "outputId": "0bd11b92-7ed6-4578-c7cf-a32ab6044d81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.classify import NaiveBayesClassifier\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "\n",
        "lemmatiser = WordNetLemmatizer()\n",
        "useless_words = stopwords.words(\"english\")\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "unique_type_list = ['INFJ', 'ENTP', 'INTP', 'INTJ', 'ENTJ', 'ENFJ', 'INFP', 'ENFP',\n",
        "       'ISFP', 'ISTP', 'ISFJ', 'ISTJ', 'ESTP', 'ESFP', 'ESTJ', 'ESFJ']\n",
        "lab_encoder = LabelEncoder().fit(unique_type_list)\n",
        "print(lab_encoder)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRLYqTTzXZcR",
        "outputId": "73d4e6db-f5e0-49e5-977e-bd5f6dad06e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LabelEncoder()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the MBTI personality into 4 letters and binarizing it\n",
        "\n",
        "b_Pers = {'I':0, 'E':1, 'N':0, 'S':1, 'F':0, 'T':1, 'J':0, 'P':1}\n",
        "b_Pers_list = [{0:'I', 1:'E'}, {0:'N', 1:'S'}, {0:'F', 1:'T'}, {0:'J', 1:'P'}]\n",
        "\n",
        "def translate_personality(personality):\n",
        "    # transform mbti to binary vector\n",
        "    return [b_Pers[l] for l in personality]\n",
        "\n",
        "#To show result output for personality prediction\n",
        "def translate_back(personality):\n",
        "    # transform binary vector to mbti personality\n",
        "    s = \"\"\n",
        "    for i, l in enumerate(personality):\n",
        "        s += b_Pers_list[i][l]\n",
        "    return s\n",
        "\n",
        "list_personality_bin = np.array([translate_personality(p) for p in data.type])\n",
        "print(\"Binarize MBTI list: \\n%s\" % list_personality_bin)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7-2HUjKZT5f",
        "outputId": "6833daa4-deee-4048-dc32-c141fced102d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Binarize MBTI list: \n",
            "[[0 0 0 0]\n",
            " [1 0 1 1]\n",
            " [0 0 1 1]\n",
            " ...\n",
            " [0 0 1 1]\n",
            " [0 0 0 1]\n",
            " [0 0 0 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def pre_process_text(data, remove_stop_words=True, remove_mbti_profiles=True):\n",
        "  list_personality = []\n",
        "  list_posts = []\n",
        "  len_data = len(data)\n",
        "  i=0\n",
        "  \n",
        "  for row in data.iterrows():\n",
        "\n",
        "      #Remove and clean comments\n",
        "      posts = row[1].posts\n",
        "\n",
        "      #Remove url links \n",
        "      temp = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' ', posts)\n",
        "\n",
        "      #Remove Non-words - keep only words\n",
        "      temp = re.sub(\"[^a-zA-Z]\", \" \", temp)\n",
        "\n",
        "      # Remove spaces > 1\n",
        "      temp = re.sub(' +', ' ', temp).lower()\n",
        "\n",
        "      #Remove multiple letter repeating words\n",
        "      temp = re.sub(r'([a-z])\\1{2,}[\\s|\\w]*', '', temp)\n",
        "\n",
        "      #Remove stop words\n",
        "      if remove_stop_words:\n",
        "          temp = \" \".join([lemmatiser.lemmatize(w) for w in temp.split(' ') if w not in useless_words])\n",
        "      else:\n",
        "          temp = \" \".join([lemmatiser.lemmatize(w) for w in temp.split(' ')])\n",
        "          \n",
        "      #Remove MBTI personality words from posts\n",
        "      if remove_mbti_profiles:\n",
        "          for t in unique_type_list:\n",
        "              temp = temp.replace(t,\"\")\n",
        "\n",
        "      # transform mbti to binary vector\n",
        "      type_labelized = translate_personality(row[1].type) #or use lab_encoder.transform([row[1].type])[0]\n",
        "      list_personality.append(type_labelized)\n",
        "      # the cleaned data temp is passed here\n",
        "      list_posts.append(temp)\n",
        "\n",
        "  # returns the result\n",
        "  list_posts = np.array(list_posts)\n",
        "  list_personality = np.array(list_personality)\n",
        "  return list_posts, list_personality\n",
        "\n",
        "list_posts, list_personality  = pre_process_text(data, remove_stop_words=True, remove_mbti_profiles=True)\n",
        "\n",
        "print(\"Example :\")\n",
        "print(\"\\nPost before preprocessing:\\n\\n\", data.posts[0])\n",
        "print(\"\\nPost after preprocessing:\\n\\n\", list_posts[0])\n",
        "print(\"\\nMBTI before preprocessing:\\n\\n\", data.type[0])\n",
        "print(\"\\nMBTI after preprocessing:\\n\\n\", list_personality[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQYYeKQtZeOB",
        "outputId": "c8b90317-3fd6-4dfb-d760-4d00eebe35ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example :\n",
            "\n",
            "Post before preprocessing:\n",
            "\n",
            " 'http://www.youtube.com/watch?v=qsXHcwe3krw|||http://41.media.tumblr.com/tumblr_lfouy03PMA1qa1rooo1_500.jpg|||enfp and intj moments  https://www.youtube.com/watch?v=iz7lE1g4XM4  sportscenter not top ten plays  https://www.youtube.com/watch?v=uCdfze1etec  pranks|||What has been the most life-changing experience in your life?|||http://www.youtube.com/watch?v=vXZeYwwRDw8   http://www.youtube.com/watch?v=u8ejam5DP3E  On repeat for most of today.|||May the PerC Experience immerse you.|||The last thing my INFJ friend posted on his facebook before committing suicide the next day. Rest in peace~   http://vimeo.com/22842206|||Hello ENFJ7. Sorry to hear of your distress. It's only natural for a relationship to not be perfection all the time in every moment of existence. Try to figure the hard times as times of growth, as...|||84389  84390  http://wallpaperpassion.com/upload/23700/friendship-boy-and-girl-wallpaper.jpg  http://assets.dornob.com/wp-content/uploads/2010/04/round-home-design.jpg ...|||Welcome and stuff.|||http://playeressence.com/wp-content/uploads/2013/08/RED-red-the-pokemon-master-32560474-450-338.jpg  Game. Set. Match.|||Prozac, wellbrutin, at least thirty minutes of moving your legs (and I don't mean moving them while sitting in your same desk chair), weed in moderation (maybe try edibles as a healthier alternative...|||Basically come up with three items you've determined that each type (or whichever types you want to do) would more than likely use, given each types' cognitive functions and whatnot, when left by...|||All things in moderation.  Sims is indeed a video game, and a good one at that. Note: a good one at that is somewhat subjective in that I am not completely promoting the death of any given Sim...|||Dear ENFP:  What were your favorite video games growing up and what are your now, current favorite video games? :cool:|||https://www.youtube.com/watch?v=QyPqT8umzmY|||It appears to be too late. :sad:|||There's someone out there for everyone.|||Wait... I thought confidence was a good thing.|||I just cherish the time of solitude b/c i revel within my inner world more whereas most other time i'd be workin... just enjoy the me time while you can. Don't worry, people will always be around to...|||Yo entp ladies... if you're into a complimentary personality,well, hey.|||... when your main social outlet is xbox live conversations and even then you verbally fatigue quickly.|||http://www.youtube.com/watch?v=gDhy7rdfm14  I really dig the part from 1:46 to 2:50|||http://www.youtube.com/watch?v=msqXffgh7b8|||Banned because this thread requires it of me.|||Get high in backyard, roast and eat marshmellows in backyard while conversing over something intellectual, followed by massages and kisses.|||http://www.youtube.com/watch?v=Mw7eoU3BMbE|||http://www.youtube.com/watch?v=4V2uYORhQOk|||http://www.youtube.com/watch?v=SlVmgFQQ0TI|||Banned for too many b's in that sentence. How could you! Think of the B!|||Banned for watching movies in the corner with the dunces.|||Banned because Health class clearly taught you nothing about peer pressure.|||Banned for a whole host of reasons!|||http://www.youtube.com/watch?v=IRcrv41hgz4|||1) Two baby deer on left and right munching on a beetle in the middle.  2) Using their own blood, two cavemen diary today's latest happenings on their designated cave diary wall.  3) I see it as...|||a pokemon world  an infj society  everyone becomes an optimist|||49142|||http://www.youtube.com/watch?v=ZRCEq_JFeFM|||http://discovermagazine.com/2012/jul-aug/20-things-you-didnt-know-about-deserts/desert.jpg|||http://oyster.ignimgs.com/mediawiki/apis.ign.com/pokemon-silver-version/d/dd/Ditto.gif|||http://www.serebii.net/potw-dp/Scizor.jpg|||Not all artists are artists because they draw. It's the idea that counts in forming something of your own... like a signature.|||Welcome to the robot ranks, person who downed my self-esteem cuz I'm not an avid signature artist like herself. :proud:|||Banned for taking all the room under my bed. Ya gotta learn to share with the roaches.|||http://www.youtube.com/watch?v=w8IgImn57aQ|||Banned for being too much of a thundering, grumbling kind of storm... yep.|||Ahh... old high school music I haven't heard in ages.   http://www.youtube.com/watch?v=dcCRUPCdB1w|||I failed a public speaking class a few years ago and I've sort of learned what I could do better were I to be in that position again. A big part of my failure was just overloading myself with too...|||I like this person's mentality. He's a confirmed INTJ by the way. http://www.youtube.com/watch?v=hGKLI-GEc6M|||Move to the Denver area and start a new life for myself.'\n",
            "\n",
            "Post after preprocessing:\n",
            "\n",
            "  enfp intj moment sportscenter top ten play prank life changing experience life repeat today may perc experience immerse last thing infj friend posted facebook committing suicide next day rest peace hello enfj sorry hear distress natural relationship perfection time every moment existence try figure hard time time growth welcome stuff game set match prozac wellbrutin least thirty minute moving leg mean moving sitting desk chair weed moderation maybe try edible healthier alternative basically come three item determined type whichever type want would likely use given type cognitive function whatnot left thing moderation sims indeed video game good one note good one somewhat subjective completely promoting death given sim dear enfp favorite video game growing current favorite video game cool appears late sad someone everyone wait thought confidence good thing cherish time solitude b c revel within inner world whereas time workin enjoy time worry people always around yo entp lady complimentary personality well hey main social outlet xbox live conversation even verbally fatigue quickly really dig part banned thread requires get high backyard roast eat marshmellows backyard conversing something intellectual followed massage kiss banned many b sentence could think b banned watching movie corner dunce banned health class clearly taught nothing peer pressure banned whole host reason two baby deer left right munching beetle middle using blood two caveman diary today latest happening designated cave diary wall see pokemon world infj society everyone becomes optimist artist artist draw idea count forming something like signature welcome robot rank person downed self esteem cuz avid signature artist like proud banned taking room bed ya gotta learn share roach banned much thundering grumbling kind storm yep ahh old high school music heard age failed public speaking class year ago sort learned could better position big part failure overloading like person mentality confirmed intj way move denver area start new life \n",
            "\n",
            "MBTI before preprocessing:\n",
            "\n",
            " INFJ\n",
            "\n",
            "MBTI after preprocessing:\n",
            "\n",
            " [0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "import sklearn.cluster as cluster\n",
        "from sklearn.manifold import TSNE\n",
        "# Vectorizing the database posts to a matrix of token counts for the model\n",
        "cntizer = CountVectorizer(analyzer=\"word\", \n",
        "                             max_features=1000,  \n",
        "                             max_df=0.7,\n",
        "                             min_df=0.1) \n",
        "\n",
        "# the feature should be made of word n-gram \n",
        "# Learn the vocabulary dictionary and return term-document matrix\n",
        "print(\"Using CountVectorizer :\")\n",
        "X_cnt = cntizer.fit_transform(list_posts)\n",
        "\n",
        "#The enumerate object yields pairs containing a count and a value (useful for obtaining an indexed list)\n",
        "feature_names = list(enumerate(cntizer.get_feature_names()))\n",
        "print(\"10 feature names can be seen below\")\n",
        "print(feature_names[0:10])\n",
        "\n",
        "# For the Standardization or Feature Scaling Stage :-\n",
        "# Transform the count matrix to a normalized tf or tf-idf representation\n",
        "tfizer = TfidfTransformer()\n",
        "\n",
        "# Learn the idf vector (fit) and transform a count matrix to a tf-idf representation\n",
        "print(\"\\nUsing Tf-idf :\")\n",
        "\n",
        "print(\"Now the dataset size is as below\")\n",
        "X_tfidf =  tfizer.fit_transform(X_cnt).toarray()\n",
        "print(X_tfidf.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KJbAHj1kwMa",
        "outputId": "c8285cce-b1ea-437c-d5c8-01eedeadd69f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using CountVectorizer :\n",
            "10 feature names can be seen below\n",
            "[(0, 'ability'), (1, 'able'), (2, 'absolutely'), (3, 'across'), (4, 'act'), (5, 'action'), (6, 'actually'), (7, 'add'), (8, 'advice'), (9, 'afraid')]\n",
            "\n",
            "Using Tf-idf :\n",
            "Now the dataset size is as below\n",
            "(8675, 615)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "personality_type = [ \"IE: Introversion (I) / Extroversion (E)\", \"NS: Intuition (N) / Sensing (S)\", \n",
        "                   \"FT: Feeling (F) / Thinking (T)\", \"JP: Judging (J) / Perceiving (P)\"  ]\n",
        "\n",
        "for l in range(len(personality_type)):\n",
        "    print(personality_type[l])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HRFEC74laRy",
        "outputId": "3326ea30-e998-4659-c776-cc868171a188"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IE: Introversion (I) / Extroversion (E)\n",
            "NS: Intuition (N) / Sensing (S)\n",
            "FT: Feeling (F) / Thinking (T)\n",
            "JP: Judging (J) / Perceiving (P)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X: 1st posts in tf-idf representation\\n%s\" % X_tfidf[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkTfgT8Ul6mw",
        "outputId": "b6e0ba8f-784a-4ba5-9117-bc8dd80cb404"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X: 1st posts in tf-idf representation\n",
            "[0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.07867715 0.06858791\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.04384368 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.05165586 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.08460784 0.         0.         0.\n",
            " 0.         0.         0.         0.05344788 0.06879666 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.16099409 0.         0.         0.09392354 0.\n",
            " 0.         0.04824874 0.         0.         0.         0.\n",
            " 0.07180073 0.         0.         0.         0.         0.\n",
            " 0.         0.07261021 0.07415792 0.08916323 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.04983073 0.         0.09165742\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.09373809 0.         0.         0.         0.\n",
            " 0.         0.         0.08087111 0.13257789 0.         0.06854893\n",
            " 0.         0.         0.         0.07132562 0.         0.\n",
            " 0.         0.         0.         0.         0.04276263 0.\n",
            " 0.05720652 0.1149078  0.         0.         0.         0.\n",
            " 0.12086262 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.1542064  0.         0.\n",
            " 0.         0.         0.         0.         0.         0.08187905\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.04340754 0.         0.         0.         0.06856192\n",
            " 0.         0.         0.28444877 0.         0.         0.\n",
            " 0.         0.         0.         0.17609293 0.         0.\n",
            " 0.         0.         0.         0.12196192 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.05663158 0.\n",
            " 0.         0.07768352 0.08187905 0.         0.         0.08848055\n",
            " 0.         0.07949719 0.         0.13017709 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.05466382\n",
            " 0.         0.         0.         0.120686   0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.1184751  0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.05394706\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.0593415  0.09171485 0.         0.         0.         0.\n",
            " 0.         0.         0.07698158 0.09075357 0.         0.06192324\n",
            " 0.         0.16657353 0.         0.         0.         0.13033776\n",
            " 0.         0.         0.07771906 0.         0.         0.\n",
            " 0.         0.         0.         0.06683467 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.09506174\n",
            " 0.         0.         0.         0.         0.05114406 0.\n",
            " 0.0581816  0.0531708  0.         0.04850869 0.         0.\n",
            " 0.         0.         0.         0.         0.09577983 0.\n",
            " 0.         0.         0.09209094 0.         0.14891697 0.\n",
            " 0.         0.         0.         0.         0.0855463  0.07464992\n",
            " 0.06967392 0.         0.         0.09554942 0.         0.\n",
            " 0.         0.         0.         0.05766763 0.07947829 0.\n",
            " 0.         0.         0.         0.         0.0933099  0.0620788\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.0676918  0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.11713239 0.         0.         0.         0.\n",
            " 0.         0.09390341 0.         0.05977062 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.07228372\n",
            " 0.         0.         0.         0.         0.         0.08729587\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.09611218 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.0577213  0.         0.         0.\n",
            " 0.05701361 0.         0.         0.         0.         0.09352321\n",
            " 0.         0.04665005 0.         0.0870499  0.         0.\n",
            " 0.08350283 0.         0.         0.         0.         0.06132943\n",
            " 0.         0.         0.         0.04131964 0.         0.\n",
            " 0.         0.         0.06447251 0.         0.         0.\n",
            " 0.08931561 0.         0.         0.08067363 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.0676666  0.09273867 0.04490286 0.08281297 0.\n",
            " 0.         0.         0.06600202 0.0724762  0.         0.\n",
            " 0.         0.09554942 0.         0.         0.         0.06311609\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.06667596 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.0783119  0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.04532701 0.0523923\n",
            " 0.08503898 0.         0.14888517 0.         0.         0.\n",
            " 0.         0.09025721 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.10270404 0.         0.         0.10775269 0.12969813 0.\n",
            " 0.         0.         0.05869553 0.         0.08016638 0.\n",
            " 0.         0.23220213 0.         0.08947488 0.         0.04100004\n",
            " 0.         0.         0.08411647 0.03990582 0.         0.\n",
            " 0.15952605 0.03996906 0.         0.         0.         0.07019125\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.11131222 0.09111738 0.         0.\n",
            " 0.         0.         0.         0.         0.0469146  0.\n",
            " 0.         0.         0.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"For MBTI personality type : %s\" % translate_back(list_personality[0,:]))\n",
        "print(\"Y : Binarized MBTI 1st row: %s\" % list_personality[0,:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DBfhuGFmMho",
        "outputId": "b498d09c-4bea-44af-af13-07c403d4628b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For MBTI personality type : INFJ\n",
            "Y : Binarized MBTI 1st row: [0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Posts in tf-idf representation\n",
        "X = X_tfidf\n"
      ],
      "metadata": {
        "id": "QlsToGPJmUYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Random Forest model for MBTI dataset\n",
        "# Individually training each mbti personlity type\n",
        "for l in range(len(personality_type)):\n",
        "    \n",
        "    Y = list_personality[:,l]\n",
        "\n",
        "    # split data into train and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=7)\n",
        "\n",
        "    # fit model on training data\n",
        "    model = RandomForestClassifier()\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # make predictions for test data\n",
        "    y_pred = model.predict(X_test)\n",
        "    \n",
        "    predictions = [round(value) for value in y_pred]\n",
        "    # evaluate predictions\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    \n",
        "    print(\"%s Accuracy: %.2f%%\" % (personality_type[l], accuracy * 100.0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSP6jqRWzlSR",
        "outputId": "a29b8ebc-7b99-4012-f92d-a6301ae371e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IE: Introversion (I) / Extroversion (E) Accuracy: 78.48%\n",
            "NS: Intuition (N) / Sensing (S) Accuracy: 86.34%\n",
            "FT: Feeling (F) / Thinking (T) Accuracy: 78.34%\n",
            "JP: Judging (J) / Perceiving (P) Accuracy: 73.56%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from xgboost import plot_importance\n",
        "#XGBoost model for MBTI dataset \n",
        "# Individually training each mbti personlity type\n",
        "for l in range(len(personality_type)):\n",
        "    \n",
        "    Y = list_personality[:,l]\n",
        "\n",
        "    # split data into train and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=7)\n",
        "\n",
        "    # fit model on training data\n",
        "    model = XGBClassifier()\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # make predictions for test data\n",
        "    y_pred = model.predict(X_test)\n",
        "    predictions = [round(value) for value in y_pred]\n",
        "    # evaluate predictions\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    \n",
        "    print(\"%s Accuracy: %.2f%%\" % (personality_type[l], accuracy * 100.0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzEWCRqcn8XW",
        "outputId": "36175314-c03f-4e5c-d1ee-b36d2d37642c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IE: Introversion (I) / Extroversion (E) Accuracy: 82.99%\n",
            "NS: Intuition (N) / Sensing (S) Accuracy: 88.40%\n",
            "FT: Feeling (F) / Thinking (T) Accuracy: 81.10%\n",
            "JP: Judging (J) / Perceiving (P) Accuracy: 76.84%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "# Logistic Regression for MBTI dataset\n",
        "# Individually training each mbti personlity type\n",
        "for l in range(len(personality_type)):\n",
        "\n",
        "    Y = list_personality[:,l]\n",
        "\n",
        "    # split data into train and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=7)\n",
        "\n",
        "    # fit model on training data\n",
        "    model = LogisticRegression() \n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # make predictions for test data\n",
        "    y_pred = model.predict(X_test)\n",
        "    \n",
        "    predictions = [round(value) for value in y_pred]\n",
        "    # evaluate predictions\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    \n",
        "    print(\"%s Accuracy: %.2f%%\" % (personality_type[l], accuracy * 100.0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9Za_XRPojwV",
        "outputId": "1b9d003d-5f8e-44a6-ec15-228224839f81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IE: Introversion (I) / Extroversion (E) Accuracy: 82.36%\n",
            "NS: Intuition (N) / Sensing (S) Accuracy: 87.67%\n",
            "FT: Feeling (F) / Thinking (T) Accuracy: 82.29%\n",
            "JP: Judging (J) / Perceiving (P) Accuracy: 76.84%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "#2 KNN model for MBTI dataset\n",
        "# Individually training each mbti personlity type\n",
        "for l in range(len(personality_type)):\n",
        "\n",
        "    Y = list_personality[:,l]\n",
        "\n",
        "    # split data into train and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=7)\n",
        "\n",
        "    # fit model on training data\n",
        "    model = KNeighborsClassifier(n_neighbors = 2)  # n_neighbors means k\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # make predictions for test data\n",
        "    y_pred = model.predict(X_test)\n",
        "    \n",
        "    predictions = [round(value) for value in y_pred]\n",
        "    # evaluate predictions\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "   \n",
        "    print(\"%s Accuracy: %.2f%%\" % (personality_type[l], accuracy * 100.0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nl2eR5JBo0Ls",
        "outputId": "d6a3f97c-2976-4744-877f-8970c862bc8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IE: Introversion (I) / Extroversion (E) Accuracy: 77.58%\n",
            "NS: Intuition (N) / Sensing (S) Accuracy: 86.13%\n",
            "FT: Feeling (F) / Thinking (T) Accuracy: 56.23%\n",
            "JP: Judging (J) / Perceiving (P) Accuracy: 42.40%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setup parameters for xgboost\n",
        "param = {}\n",
        "\n",
        "param['n_estimators'] = 200 #100\n",
        "param['max_depth'] = 2 #3\n",
        "param['nthread'] = 8 #1\n",
        "param['learning_rate'] = 0.2 #0.1\n",
        "\n",
        "# Individually training each mbti personlity type\n",
        "for l in range(len(personality_type)):\n",
        "    Y = list_personality[:,l]\n",
        "\n",
        "    # split data into train and test sets\n",
        "    seed = 7\n",
        "    test_size = 0.33\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
        "\n",
        "    # fit model on training data\n",
        "    model = XGBClassifier(**param)\n",
        "    model.fit(X_train, y_train)\n",
        "    # make predictions for test data\n",
        "    y_pred = model.predict(X_test)\n",
        "    predictions = [round(value) for value in y_pred]\n",
        "    # evaluate predictions\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    print(\"%s Accuracy: %.2f%%\" % (personality_type[l], accuracy * 100.0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qyvK0Z3pGn7",
        "outputId": "f0c8ce86-c2a6-4577-b597-afb7d8a90781"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IE: Introversion (I) / Extroversion (E) Accuracy: 82.50%\n",
            "NS: Intuition (N) / Sensing (S) Accuracy: 88.33%\n",
            "FT: Feeling (F) / Thinking (T) Accuracy: 80.96%\n",
            "JP: Judging (J) / Perceiving (P) Accuracy: 77.09%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Recruiter1\n",
        "my_posts = \"\"\"Monday's....they're so dreadful\n",
        "\n",
        "But are they???\n",
        "\n",
        "It's a new work week. You know what that means? It's a fresh start.\n",
        "\n",
        "Fresh eyes and cleared mine to tackle that project you've been working on.\n",
        "\n",
        "Fresh eyes and clear mind to take on new projects.\n",
        "\n",
        "Fresh eyes and clear mind to redo your resume, search for new jobs, and apply.\n",
        "\n",
        "Monday's are your chance for a new beginning.\n",
        "\"\"\"\n",
        "\n",
        "mydata = pd.DataFrame(data={'type': ['INFJ'], 'posts': [my_posts]})\n",
        "\n",
        "my_posts, dummy  = pre_process_text(mydata, remove_stop_words=True, remove_mbti_profiles=True)\n",
        "\n",
        "my_X_cnt = cntizer.transform(my_posts)\n",
        "my_X_tfidf =  tfizer.transform(my_X_cnt).toarray()"
      ],
      "metadata": {
        "id": "R41qxp6Xpes4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setup parameters for xgboost\n",
        "param = {}\n",
        "param['n_estimators'] = 200\n",
        "param['max_depth'] = 2\n",
        "param['nthread'] = 8\n",
        "param['learning_rate'] = 0.2\n",
        "\n",
        "#XGBoost model for MBTI dataset\n",
        "result = []\n",
        "# Individually training each mbti personlity type\n",
        "for l in range(len(personality_type)):\n",
        "    print(\"%s classifier trained\" % (personality_type[l]))\n",
        "    \n",
        "    Y = list_personality[:,l]\n",
        "\n",
        "    # split data into train and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=7)\n",
        "\n",
        "    # fit model on training data\n",
        "    model = XGBClassifier(**param)\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    # make predictions for my  data\n",
        "    y_pred = model.predict(my_X_tfidf)\n",
        "    result.append(y_pred[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSe0HiVgGvlI",
        "outputId": "dd9671f2-e2d6-4d26-be08-6e35f5d96ae0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IE: Introversion (I) / Extroversion (E) classifier trained\n",
            "NS: Intuition (N) / Sensing (S) classifier trained\n",
            "FT: Feeling (F) / Thinking (T) classifier trained\n",
            "JP: Judging (J) / Perceiving (P) classifier trained\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The result is: \", translate_back(result))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqRsalaJGzm4",
        "outputId": "150dbcd6-8ecd-49e2-9f87-8ae15975ff34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The result is:  INFP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Recruiter1 \n",
        "my_posts = \"\"\"Career cushioning: verb - applying to jobs while you're in one in the case you need a backup due to unforeseen or anticipated layoff.\n",
        "\n",
        "I've been talking to a lot of professionals this past quarter who are worried about mass layoffs and the recession.\n",
        "\n",
        "They've dusted off their resumes and are proactively networking / putting out feelers in case something happens.\n",
        "\n",
        "The feeling of being proactive vs reactive gives them a sense of security.\n",
        "\n",
        "I am a fan of career cushioning because I believe the best way to recession proof yourself is to master job search skills.\n",
        "\n",
        " Being unphased by headlines because you know you're in full control of your career + 100% marketable is the most liberating feeling.\n",
        "\n",
        "Let me know in the poll if you have found yourself career cushioning before! I know I have, without even realizing there was a term lol\"\"\"\n",
        "\n",
        "mydata = pd.DataFrame(data={'type': ['INFJ'], 'posts': [my_posts]})\n",
        "\n",
        "my_posts, dummy  = pre_process_text(mydata, remove_stop_words=True, remove_mbti_profiles=True)\n",
        "\n",
        "my_X_cnt = cntizer.transform(my_posts)\n",
        "my_X_tfidf =  tfizer.transform(my_X_cnt).toarray()"
      ],
      "metadata": {
        "id": "GF2bBk_6I4rM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setup parameters for xgboost\n",
        "param = {}\n",
        "param['n_estimators'] = 200\n",
        "param['max_depth'] = 2\n",
        "param['nthread'] = 8\n",
        "param['learning_rate'] = 0.2\n",
        "\n",
        "#XGBoost model for MBTI dataset\n",
        "result = []\n",
        "# Individually training each mbti personlity type\n",
        "for l in range(len(personality_type)):\n",
        "    print(\"%s classifier trained\" % (personality_type[l]))\n",
        "    \n",
        "    Y = list_personality[:,l]\n",
        "\n",
        "    # split data into train and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=7)\n",
        "\n",
        "    # fit model on training data\n",
        "    model = XGBClassifier(**param)\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    # make predictions for my  data\n",
        "    y_pred = model.predict(my_X_tfidf)\n",
        "    result.append(y_pred[0])"
      ],
      "metadata": {
        "id": "1F4bdDN0I4UE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The result is: \", translate_back(result))"
      ],
      "metadata": {
        "id": "xtSSULmgJHUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Recruiter1\n",
        "my_posts = \"\"\"My mom visited my brother and noticed high quality, like new pots laying next to the trash can.\n",
        "\n",
        "These are practically new and such great quality - why are you tossing these?\n",
        "\n",
        "My brother responded they got a new set - admittedly not as quality material - but they decided to keep them.\n",
        "\n",
        "Meanwhile, my mom stays at my house a lot and has been complaining about having a pot shortage.\n",
        "\n",
        "(I cook with one for everything. Now I get why there are 6 burners on the stove lol)\n",
        "\n",
        "She happily brought them over and they accompany our og pot.\n",
        "\n",
        "We couldnt be more impressed and happy with them!\n",
        "\n",
        "They are exactly what we needed at the right time.\n",
        "\n",
        "Pots are kind of like talent.\n",
        "\n",
        "All unique and have a match somewhere, ready to find a new org and be their treasure. \"\"\"\n",
        "\n",
        "mydata = pd.DataFrame(data={'type': ['INFJ'], 'posts': [my_posts]})\n",
        "\n",
        "my_posts, dummy  = pre_process_text(mydata, remove_stop_words=True, remove_mbti_profiles=True)\n",
        "\n",
        "my_X_cnt = cntizer.transform(my_posts)\n",
        "my_X_tfidf =  tfizer.transform(my_X_cnt).toarray()"
      ],
      "metadata": {
        "id": "NCvXtC4aJgRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setup parameters for xgboost\n",
        "param = {}\n",
        "param['n_estimators'] = 200\n",
        "param['max_depth'] = 2\n",
        "param['nthread'] = 8\n",
        "param['learning_rate'] = 0.2\n",
        "\n",
        "#XGBoost model for MBTI dataset\n",
        "result = []\n",
        "# Individually training each mbti personlity type\n",
        "for l in range(len(personality_type)):\n",
        "    print(\"%s classifier trained\" % (personality_type[l]))\n",
        "    \n",
        "    Y = list_personality[:,l]\n",
        "\n",
        "    # split data into train and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=7)\n",
        "\n",
        "    # fit model on training data\n",
        "    model = XGBClassifier(**param)\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    # make predictions for my  data\n",
        "    y_pred = model.predict(my_X_tfidf)\n",
        "    result.append(y_pred[0])"
      ],
      "metadata": {
        "id": "0slrtIZfJh2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The result is: \", translate_back(result))"
      ],
      "metadata": {
        "id": "KIP07aGlJlzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Recruiter2\n",
        "my_posts = \"\"\"Yesterday was.... wow. Yesterday was for #meta but today will be for me \n",
        "\n",
        "I am now #opentowork due to the #metalayoff and want to put my passions for people, improvement, and organization to work.\n",
        "\n",
        "Yes - I love the recruiting space.\n",
        "However - PLEASE don't count me out for your HR operations, Executive Admin, and Analyst positions; there are many transferable skillsets I would love to tell you more about.\n",
        "\n",
        "With gratitude and the right attitude, we're keeping it moving!\"\"\"\n",
        "\n",
        "mydata = pd.DataFrame(data={'type': ['INFJ'], 'posts': [my_posts]})\n",
        "\n",
        "my_posts, dummy  = pre_process_text(mydata, remove_stop_words=True, remove_mbti_profiles=True)\n",
        "\n",
        "my_X_cnt = cntizer.transform(my_posts)\n",
        "my_X_tfidf =  tfizer.transform(my_X_cnt).toarray()"
      ],
      "metadata": {
        "id": "ttgLIZvmJ7yv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setup parameters for xgboost\n",
        "param = {}\n",
        "param['n_estimators'] = 200\n",
        "param['max_depth'] = 2\n",
        "param['nthread'] = 8\n",
        "param['learning_rate'] = 0.2\n",
        "\n",
        "#XGBoost model for MBTI dataset\n",
        "result = []\n",
        "# Individually training each mbti personlity type\n",
        "for l in range(len(personality_type)):\n",
        "    print(\"%s classifier trained\" % (personality_type[l]))\n",
        "    \n",
        "    Y = list_personality[:,l]\n",
        "\n",
        "    # split data into train and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=7)\n",
        "\n",
        "    # fit model on training data\n",
        "    model = XGBClassifier(**param)\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    # make predictions for my  data\n",
        "    y_pred = model.predict(my_X_tfidf)\n",
        "    result.append(y_pred[0])"
      ],
      "metadata": {
        "id": "MvnlDmSPw3sy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The result is: \", translate_back(result))"
      ],
      "metadata": {
        "id": "V_bMBy_nw4gP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Recruiter2\n",
        "my_posts = \"\"\"Reasons you might want to be mean to a recruiter:\n",
        "\n",
        "They clearly didn't read your resume/profile\n",
        "They misspelled your name\n",
        "They won't share salary information\n",
        " They pressure you to make quick decisions\n",
        "\n",
        "AND THOSE ARE ALL VALID  BUT here's how to respond and maintain YOUR professionalism:\n",
        "\n",
        " \"I appreciate the message, however I am only seeking roles in XYZ Industry with XYZ Title - best of luck in your search!\"\n",
        "\n",
        " \"Hello! My name is actually spelled _______ autocorrect can be annoying sometimes huh??\"\n",
        "\n",
        " \"In the interest of both our time and my current employment, I'll need a starting point for compensation before moving forward\"\n",
        "\n",
        " \"Currently, I'm in no rush to make a move - I'm carefully evaluating all my options. I should have an answer by _____ if that does not suit your timeline, please let me know!\"\n",
        "\n",
        "\n",
        "No one regrets being kind, and our networks today are more powerful than ever - let's keep them healthy.\"\"\"\n",
        "\n",
        "mydata = pd.DataFrame(data={'type': ['INFJ'], 'posts': [my_posts]})\n",
        "\n",
        "my_posts, dummy  = pre_process_text(mydata, remove_stop_words=True, remove_mbti_profiles=True)\n",
        "\n",
        "my_X_cnt = cntizer.transform(my_posts)\n",
        "my_X_tfidf =  tfizer.transform(my_X_cnt).toarray()"
      ],
      "metadata": {
        "id": "yqup2csFzCua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setup parameters for xgboost\n",
        "param = {}\n",
        "param['n_estimators'] = 200\n",
        "param['max_depth'] = 2\n",
        "param['nthread'] = 8\n",
        "param['learning_rate'] = 0.2\n",
        "\n",
        "#XGBoost model for MBTI dataset\n",
        "result = []\n",
        "# Individually training each mbti personlity type\n",
        "for l in range(len(personality_type)):\n",
        "    print(\"%s classifier trained\" % (personality_type[l]))\n",
        "    \n",
        "    Y = list_personality[:,l]\n",
        "\n",
        "    # split data into train and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=7)\n",
        "\n",
        "    # fit model on training data\n",
        "    model = XGBClassifier(**param)\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    # make predictions for my  data\n",
        "    y_pred = model.predict(my_X_tfidf)\n",
        "    result.append(y_pred[0])"
      ],
      "metadata": {
        "id": "aViKtm3GzHKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The result is: \", translate_back(result))"
      ],
      "metadata": {
        "id": "auTv-r2GzJES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Recruiter2\n",
        "my_posts = \"\"\"APPARENTLY this needs to be said to CONTRACT workers:\n",
        "\n",
        "Don't listen to those viral posts telling you you can't use the word 'layoff'. Those posts give HR and recruiters a bad name and it's so disappointing. We don't all feel that way.\n",
        "\n",
        "When your employment is cut short due to budget (especially along with 100s or 1,000s of your CW teammates) no one should care what words you use to describe your loss. These are such insane times, let's use our platforms to uplift and connect - we are focused on all the wrong things.\n",
        "\n",
        "\"They were never part of the company\" ....??? Give me a break.\n",
        "\"\"\"\n",
        "\n",
        "mydata = pd.DataFrame(data={'type': ['INFJ'], 'posts': [my_posts]})\n",
        "\n",
        "my_posts, dummy  = pre_process_text(mydata, remove_stop_words=True, remove_mbti_profiles=True)\n",
        "\n",
        "my_X_cnt = cntizer.transform(my_posts)\n",
        "my_X_tfidf =  tfizer.transform(my_X_cnt).toarray()"
      ],
      "metadata": {
        "id": "KgCW3RNj499g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setup parameters for xgboost\n",
        "param = {}\n",
        "param['n_estimators'] = 200\n",
        "param['max_depth'] = 2\n",
        "param['nthread'] = 8\n",
        "param['learning_rate'] = 0.2\n",
        "\n",
        "#XGBoost model for MBTI dataset\n",
        "result = []\n",
        "# Individually training each mbti personlity type\n",
        "for l in range(len(personality_type)):\n",
        "    print(\"%s classifier trained\" % (personality_type[l]))\n",
        "    \n",
        "    Y = list_personality[:,l]\n",
        "\n",
        "    # split data into train and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=7)\n",
        "\n",
        "    # fit model on training data\n",
        "    model = XGBClassifier(**param)\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    # make predictions for my  data\n",
        "    y_pred = model.predict(my_X_tfidf)\n",
        "    result.append(y_pred[0])"
      ],
      "metadata": {
        "id": "Z8loQ_si5Fku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The result is: \", translate_back(result))"
      ],
      "metadata": {
        "id": "Lla9enfG5KOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Recruiter3\n",
        "my_posts = \"\"\"\n",
        "Is exactly what I did! I have been distancing myself from social media, on a personal level. #selfawareness\n",
        "* I am trying to be more present for my kids and husband. #familytime\n",
        "* I have to process my own struggles before I can fully help others. #selflovematters\n",
        "* Seeing all the negative all the time is draining. ##mentalhealth\n",
        "\n",
        "We all want to assist and lend a hand where we can, but we can't do that if we are struggling too.\n",
        "\n",
        "Remember: It's ok to take a break. Everyone will still be there when you get back. Take time to reset and refresh. #breaktime #reset #refresh #nosocialmedia #putyourphonedown #comebackstronger\n",
        "\n",
        "Post2: With layoffs happening all around us, this time of year has been so hard on many of us.\n",
        "\n",
        "Keep pushing forward. Find the silver lining in every situation. I know easier said than done. But please, keep your head up. Your perfect job will come along.\n",
        "\n",
        "You are not alone. There are many of us is the same boat, all trying to stay afloat. There are also a ton of people cheering us on.\n",
        "\n",
        "Don't be afraid to reach out to hiring managers & job posters.\"\"\"\n",
        "\n",
        "mydata = pd.DataFrame(data={'type': ['INFJ'], 'posts': [my_posts]})\n",
        "\n",
        "my_posts, dummy  = pre_process_text(mydata, remove_stop_words=True, remove_mbti_profiles=True)\n",
        "\n",
        "my_X_cnt = cntizer.transform(my_posts)\n",
        "my_X_tfidf =  tfizer.transform(my_X_cnt).toarray()"
      ],
      "metadata": {
        "id": "VouSf2T35TlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setup parameters for xgboost\n",
        "param = {}\n",
        "param['n_estimators'] = 200\n",
        "param['max_depth'] = 2\n",
        "param['nthread'] = 8\n",
        "param['learning_rate'] = 0.2\n",
        "\n",
        "#XGBoost model for MBTI dataset\n",
        "result = []\n",
        "# Individually training each mbti personlity type\n",
        "for l in range(len(personality_type)):\n",
        "    print(\"%s classifier trained\" % (personality_type[l]))\n",
        "    \n",
        "    Y = list_personality[:,l]\n",
        "\n",
        "    # split data into train and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=7)\n",
        "\n",
        "    # fit model on training data\n",
        "    model = XGBClassifier(**param)\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    # make predictions for my  data\n",
        "    y_pred = model.predict(my_X_tfidf)\n",
        "    result.append(y_pred[0])"
      ],
      "metadata": {
        "id": "y2sWFIKv5Vzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The result is: \", translate_back(result))"
      ],
      "metadata": {
        "id": "n3bzBt755ZUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Recruiter3\n",
        "my_posts = \"\"\"\n",
        "With layoffs happening all around us, this time of year has been so hard on many of us.\n",
        "\n",
        "Keep pushing forward. Find the silver lining in every situation. I know easier said than done. But please, keep your head up. Your perfect job will come along.\n",
        "\n",
        "You are not alone. There are many of us is the same boat, all trying to stay afloat. There are also a ton of people cheering us on.\n",
        "\n",
        "Don't be afraid to reach out to hiring managers & job posters.\n",
        "\n",
        "Take advantage of others posts #opentowork #optentoconnect.\n",
        "\n",
        "Start creating your own LinkedIn posts and promote yourself. Don't be afraid to put yourself out there.\n",
        "\n",
        "Look through others connections. Take the time to connect with them. You never know who might lead you to your next adventure.\n",
        "\n",
        "We are in this together. Here to help and lend a hand.\"\"\"\n",
        "\n",
        "mydata = pd.DataFrame(data={'type': ['INFJ'], 'posts': [my_posts]})\n",
        "\n",
        "my_posts, dummy  = pre_process_text(mydata, remove_stop_words=True, remove_mbti_profiles=True)\n",
        "\n",
        "my_X_cnt = cntizer.transform(my_posts)\n",
        "my_X_tfidf =  tfizer.transform(my_X_cnt).toarray()"
      ],
      "metadata": {
        "id": "LBlzOJsT5kfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setup parameters for xgboost\n",
        "param = {}\n",
        "param['n_estimators'] = 200\n",
        "param['max_depth'] = 2\n",
        "param['nthread'] = 8\n",
        "param['learning_rate'] = 0.2\n",
        "\n",
        "#XGBoost model for MBTI dataset\n",
        "result = []\n",
        "# Individually training each mbti personlity type\n",
        "for l in range(len(personality_type)):\n",
        "    print(\"%s classifier trained\" % (personality_type[l]))\n",
        "    \n",
        "    Y = list_personality[:,l]\n",
        "\n",
        "    # split data into train and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=7)\n",
        "\n",
        "    # fit model on training data\n",
        "    model = XGBClassifier(**param)\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    # make predictions for my  data\n",
        "    y_pred = model.predict(my_X_tfidf)\n",
        "    result.append(y_pred[0])"
      ],
      "metadata": {
        "id": "KpV5Y8NS5mlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The result is: \", translate_back(result))"
      ],
      "metadata": {
        "id": "ZGYrB0NK5pK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Recruiter3\n",
        "my_posts = \"\"\"\n",
        "Monday's....they're so dreadful\n",
        "\n",
        "But are they???\n",
        "\n",
        "It's a new work week. You know what that means? It's a fresh start.\n",
        "\n",
        "Fresh eyes and cleared mine to tackle that project you've been working on.\n",
        "\n",
        "Fresh eyes and clear mind to take on new projects.\n",
        "\n",
        "Fresh eyes and clear mind to redo your resume, search for new jobs, and apply.\n",
        "\n",
        "Monday's are your chance for a new beginning.\"\"\"\n",
        "\n",
        "mydata = pd.DataFrame(data={'type': ['INFJ'], 'posts': [my_posts]})\n",
        "\n",
        "my_posts, dummy  = pre_process_text(mydata, remove_stop_words=True, remove_mbti_profiles=True)\n",
        "\n",
        "my_X_cnt = cntizer.transform(my_posts)\n",
        "my_X_tfidf =  tfizer.transform(my_X_cnt).toarray()"
      ],
      "metadata": {
        "id": "4TKmSL4Q5rig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setup parameters for xgboost\n",
        "param = {}\n",
        "param['n_estimators'] = 200\n",
        "param['max_depth'] = 2\n",
        "param['nthread'] = 8\n",
        "param['learning_rate'] = 0.2\n",
        "\n",
        "#XGBoost model for MBTI dataset\n",
        "result = []\n",
        "# Individually training each mbti personlity type\n",
        "for l in range(len(personality_type)):\n",
        "    print(\"%s classifier trained\" % (personality_type[l]))\n",
        "    \n",
        "    Y = list_personality[:,l]\n",
        "\n",
        "    # split data into train and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=7)\n",
        "\n",
        "    # fit model on training data\n",
        "    model = XGBClassifier(**param)\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    # make predictions for my  data\n",
        "    y_pred = model.predict(my_X_tfidf)\n",
        "    result.append(y_pred[0])"
      ],
      "metadata": {
        "id": "eteze0SW5659"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The result is: \", translate_back(result))"
      ],
      "metadata": {
        "id": "qVPGRcbp58s9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Recruiter3\n",
        "my_posts = \"\"\"I am utterly shocked at all these layoffs over the past few weeks. Mine happened 2 weeks ago \n",
        "\n",
        "It's like follow the leader here. Competition style-who can lay off the most.\n",
        "\n",
        "1 company starts the next is like...bet!!\n",
        "\n",
        "Domino effect activated.\n",
        "\n",
        "So heart breaking. I am truly sorry to everyone effected by layoffs.\"\"\"\n",
        "\n",
        "mydata = pd.DataFrame(data={'type': ['INFJ'], 'posts': [my_posts]})\n",
        "\n",
        "my_posts, dummy  = pre_process_text(mydata, remove_stop_words=True, remove_mbti_profiles=True)\n",
        "\n",
        "my_X_cnt = cntizer.transform(my_posts)\n",
        "my_X_tfidf =  tfizer.transform(my_X_cnt).toarray()"
      ],
      "metadata": {
        "id": "czyUr15N6Gs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setup parameters for xgboost\n",
        "param = {}\n",
        "param['n_estimators'] = 200\n",
        "param['max_depth'] = 2\n",
        "param['nthread'] = 8\n",
        "param['learning_rate'] = 0.2\n",
        "\n",
        "#XGBoost model for MBTI dataset\n",
        "result = []\n",
        "# Individually training each mbti personlity type\n",
        "for l in range(len(personality_type)):\n",
        "    print(\"%s classifier trained\" % (personality_type[l]))\n",
        "    \n",
        "    Y = list_personality[:,l]\n",
        "\n",
        "    # split data into train and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=7)\n",
        "\n",
        "    # fit model on training data\n",
        "    model = XGBClassifier(**param)\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    # make predictions for my  data\n",
        "    y_pred = model.predict(my_X_tfidf)\n",
        "    result.append(y_pred[0])"
      ],
      "metadata": {
        "id": "G-8NjqCS6Gku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The result is: \", translate_back(result))"
      ],
      "metadata": {
        "id": "VbWeoTCC6GV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Recruiter4\n",
        "my_posts = \"\"\"\n",
        "Last week, #Salesforce and #Slack ended the employment of all its 90+ recruiting org contractors. Which means...a lot of strong #talentacquisition folks out in the market!!\n",
        "\n",
        " If you are #HIRING recruiting professionals, take a look at this spreadsheet   https://lnkd.in/g7gPJssM   with some of the staff impacted by this change. If you are looking for an RC, Sourcer, or full cycle recruiter  LOTS of great talent in here! \n",
        "\n",
        "On a more personal note: \n",
        "\n",
        " Biggest shoutout  to our Salesforce/Slack team, which has been so so supportive of one another, and is a testament to this team's genuine care for people. Thankful to have worked with all of you!\n",
        "\n",
        " Last but not least, please don't discount the impact of a quick note, call, or care package to someone whos been laid off  to anyone who has done this for me in the last week, THANK YOU, youve truly been an encouragement. \n",
        "\"\"\"\n",
        "\n",
        "mydata = pd.DataFrame(data={'type': ['INFJ'], 'posts': [my_posts]})\n",
        "\n",
        "my_posts, dummy  = pre_process_text(mydata, remove_stop_words=True, remove_mbti_profiles=True)\n",
        "\n",
        "my_X_cnt = cntizer.transform(my_posts)\n",
        "my_X_tfidf =  tfizer.transform(my_X_cnt).toarray()"
      ],
      "metadata": {
        "id": "ByPrv3k66QO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setup parameters for xgboost\n",
        "param = {}\n",
        "param['n_estimators'] = 200\n",
        "param['max_depth'] = 2\n",
        "param['nthread'] = 8\n",
        "param['learning_rate'] = 0.2\n",
        "\n",
        "#XGBoost model for MBTI dataset\n",
        "result = []\n",
        "# Individually training each mbti personlity type\n",
        "for l in range(len(personality_type)):\n",
        "    print(\"%s classifier trained\" % (personality_type[l]))\n",
        "    \n",
        "    Y = list_personality[:,l]\n",
        "\n",
        "    # split data into train and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=7)\n",
        "\n",
        "    # fit model on training data\n",
        "    model = XGBClassifier(**param)\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    # make predictions for my  data\n",
        "    y_pred = model.predict(my_X_tfidf)\n",
        "    result.append(y_pred[0])"
      ],
      "metadata": {
        "id": "vYN_SXsq6QHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The result is: \", translate_back(result))"
      ],
      "metadata": {
        "id": "lFzFhF9p6QAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Recruiter4\n",
        "my_posts = \"\"\"\n",
        "I recently wrapped up the first quarter of my new role at #Salesforce as a Senior Tech Sourcing Recruiter!\n",
        "\n",
        "One of the things that has impressed me most so far is the supportive atmosphere and emphasis on employee wellness (like tomorrow's Wellness Day!). BIG thank you to my team and everyone who has helped make the transition a great experience.\n",
        "\n",
        "Side note - if you're a Software Engineer with 6+ years of experience looking for back-end roles, would love to connect! Feel free to send a resume my way at bteppen@salesforce.com. :)\n",
        "\"\"\"\n",
        "\n",
        "mydata = pd.DataFrame(data={'type': ['INFJ'], 'posts': [my_posts]})\n",
        "\n",
        "my_posts, dummy  = pre_process_text(mydata, remove_stop_words=True, remove_mbti_profiles=True)\n",
        "\n",
        "my_X_cnt = cntizer.transform(my_posts)\n",
        "my_X_tfidf =  tfizer.transform(my_X_cnt).toarray()"
      ],
      "metadata": {
        "id": "vaEj1MaZ6tpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setup parameters for xgboost\n",
        "param = {}\n",
        "param['n_estimators'] = 200\n",
        "param['max_depth'] = 2\n",
        "param['nthread'] = 8\n",
        "param['learning_rate'] = 0.2\n",
        "\n",
        "#XGBoost model for MBTI dataset\n",
        "result = []\n",
        "# Individually training each mbti personlity type\n",
        "for l in range(len(personality_type)):\n",
        "    print(\"%s classifier trained\" % (personality_type[l]))\n",
        "    \n",
        "    Y = list_personality[:,l]\n",
        "\n",
        "    # split data into train and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=7)\n",
        "\n",
        "    # fit model on training data\n",
        "    model = XGBClassifier(**param)\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    # make predictions for my  data\n",
        "    y_pred = model.predict(my_X_tfidf)\n",
        "    result.append(y_pred[0])"
      ],
      "metadata": {
        "id": "EBO7W2j76mkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The result is: \", translate_back(result))"
      ],
      "metadata": {
        "id": "6iqkobKk6sew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Recruiter4\n",
        "my_posts = \"\"\"\n",
        "Y'all. I've been so busy planning the strategy for our big hiring initiative I forgot it's Tuesday and I have to tell you all about it!!!!\n",
        "\n",
        "We're HIRING a bunch of Assembly Technicians in the new year and we are recruiting NOW! Job postings almost ready to publish, hiring managers and recruiters ready to talk to a bunch of amazing talent...\n",
        "\n",
        "Here's a little sneak peek at the requirements:\n",
        "\n",
        " High school degree or equivalency certificate\n",
        " 1+ years manufacturing work experience, or relevant trade school certification\n",
        " 1+ years of hand tools experience (i.e., Calipers, multi-meters, torque wrenches)\n",
        "\n",
        "Additional Requirements:\n",
        " Willing to work all shifts, overtime and weekends as needed. Estimated shift times 1st shift: 8am-4:30PM Shift will vary, depending on program needs\n",
        " Standing for long periods of time, climbing up and down ladders, bending, grasping, sitting, pulling, pushing, stooping, and stretching may be required to perform the functions of this position\n",
        " Able to lift up to 25lbs. unassisted\n",
        "\n",
        "I can't guarantee you'll use a similar tool as what's pictured here, but I am pretty confident the satellites you'll be building will be a bit larger than what I've got \n",
        "\n",
        "If this sounds interesting, hit us up! #ProjectKuiper recruiters standing by kuiperjobs@amazon.com. All roles based in Redmond and (soon) Kirkland - read about our new facility here - https://lnkd.in/gxGAfp-N\n",
        "\n",
        "Let's Build!\n",
        "\n",
        "#AmazonJobs #SpaceJobs #Satellites #Recruiting #Hiring\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "mydata = pd.DataFrame(data={'type': ['INFJ'], 'posts': [my_posts]})\n",
        "\n",
        "my_posts, dummy  = pre_process_text(mydata, remove_stop_words=True, remove_mbti_profiles=True)\n",
        "\n",
        "my_X_cnt = cntizer.transform(my_posts)\n",
        "my_X_tfidf =  tfizer.transform(my_X_cnt).toarray()"
      ],
      "metadata": {
        "id": "kwGwkDip6sUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setup parameters for xgboost\n",
        "param = {}\n",
        "param['n_estimators'] = 200\n",
        "param['max_depth'] = 2\n",
        "param['nthread'] = 8\n",
        "param['learning_rate'] = 0.2\n",
        "\n",
        "#XGBoost model for MBTI dataset\n",
        "result = []\n",
        "# Individually training each mbti personlity type\n",
        "for l in range(len(personality_type)):\n",
        "    print(\"%s classifier trained\" % (personality_type[l]))\n",
        "    \n",
        "    Y = list_personality[:,l]\n",
        "\n",
        "    # split data into train and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=7)\n",
        "\n",
        "    # fit model on training data\n",
        "    model = XGBClassifier(**param)\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    # make predictions for my  data\n",
        "    y_pred = model.predict(my_X_tfidf)\n",
        "    result.append(y_pred[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRN-OxJM6mc0",
        "outputId": "cb3ef019-dd26-4aa3-aefd-230bc3d5c56d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IE: Introversion (I) / Extroversion (E) classifier trained\n",
            "NS: Intuition (N) / Sensing (S) classifier trained\n",
            "FT: Feeling (F) / Thinking (T) classifier trained\n",
            "JP: Judging (J) / Perceiving (P) classifier trained\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The result is: \", translate_back(result))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRpijydO6mVU",
        "outputId": "8564bc27-8acb-4aab-c618-ae778d1db712"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The result is:  INFP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b4bozJAiPhNt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}